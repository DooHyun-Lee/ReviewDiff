{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model_class = DistilBertModel\n",
    "tokenizer_class = DistilBertTokenizer\n",
    "\n",
    "meta_data_file = \"/root/research/ReviewDiff/preprocess/data/preprocessed/meta_data.json\"\n",
    "train_data_file = \"/root/research/ReviewDiff/preprocess/data/preprocessed/train_data.json\"\n",
    "\n",
    "# Load files\n",
    "with open(meta_data_file) as file:\n",
    "    meta_data = json.load(file)\n",
    "\n",
    "with open(train_data_file) as file:\n",
    "    train_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(model, tokenizer, sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save(data, model_key, model, tokenizer, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    pickle_path = os.path.join(save_dir, f\"{model_key}/embeddings_768.pckl\")\n",
    "    os.makedirs(os.path.dirname(pickle_path), exist_ok=True)\n",
    "    \n",
    "    with open(pickle_path, \"wb\") as pckl_file:\n",
    "        for trajectory in tqdm(data, desc=\"Encoding trajectories\"):\n",
    "            attributes = [product[\"attribute\"] for product in trajectory]\n",
    "            embeddings = generate_embeddings(model, tokenizer, attributes)\n",
    "            processed_trajectory = [\n",
    "                {\n",
    "                    \"embedding\": embeddings[i],\n",
    "                    \"review\": product[\"review\"],\n",
    "                    \"asin\": product[\"asin\"],\n",
    "                }\n",
    "                for i, product in enumerate(trajectory)\n",
    "            ]\n",
    "            pickle.dump(processed_trajectory, pckl_file)\n",
    "\n",
    "    print(f\"Saved embeddings to {pickle_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoding trajectories: 100%|██████████| 5/5 [00:23<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to data/embeddings/distilbert/embeddings_768.pckl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare model\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "model = model_class.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Process\n",
    "save_dir = \"data/embeddings\"\n",
    "process_and_save(train_data[:5], model_name.split(\"-\")[0], model, tokenizer, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from data/embeddings/distilbert/embeddings_768.pckl\n",
      "Total number of trajectories: 5\n",
      "\n",
      "[FIRST TRAJECTORY]\n",
      "ASIN: B000VZGTPY\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.0578975   0.07030657  0.50867945  0.10296871  0.1382606 ]\n",
      "---------------\n",
      "ASIN: B000VZGTPY\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.0578975   0.07030657  0.50867945  0.10296871  0.1382606 ]\n",
      "---------------\n",
      "ASIN: B003O6SJEQ\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.13559039  0.06522012  0.67901325  0.09240711  0.16797067]\n",
      "---------------\n",
      "ASIN: B00BFI5SE4\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.10564767 -0.02553836  0.62826556  0.06384551  0.07079843]\n",
      "---------------\n",
      "ASIN: B00GURJZZI\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.19269682 -0.0229433   0.6225416   0.13620986  0.04851849]\n",
      "---------------\n",
      "ASIN: 7138258879\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.05758295 -0.02696746  0.56371075  0.14300363  0.17606452]\n",
      "---------------\n",
      "ASIN: B000K1PKFY\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.14850226  0.10236997  0.35682413  0.0750614   0.2582766 ]\n",
      "---------------\n",
      "ASIN: B000M5X0IM\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.11870433 -0.0311092   0.49126714  0.03915683  0.21067101]\n",
      "---------------\n",
      "ASIN: B000OCT7FI\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [0.04776968 0.13989982 0.19499524 0.11194894 0.12204533]\n",
      "---------------\n",
      "ASIN: B000PTKONY\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.04748785  0.0455364   0.4689584   0.08332497  0.30543113]\n",
      "---------------\n",
      "ASIN: B000WJFF6S\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.05667854 -0.01251237  0.5632044   0.14257109  0.1991468 ]\n",
      "---------------\n",
      "ASIN: B000WJFF6S\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.05667854 -0.01251237  0.5632044   0.14257109  0.1991468 ]\n",
      "---------------\n",
      "ASIN: B002ZTGLCK\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [ 0.06557459 -0.04844444  0.41291     0.11292792  0.20676933]\n",
      "---------------\n",
      "ASIN: B006VXZQXG\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.07680297  0.04769684  0.58397514  0.13042095  0.1155689 ]\n",
      "---------------\n",
      "ASIN: B00D7N8HRK\n",
      "Review: 4.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.11772558 -0.05011943  0.5861056   0.07476851  0.13621467]\n",
      "---------------\n",
      "ASIN: B00EO1F9I4\n",
      "Review: 4.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.02037561 -0.02780622  0.4411151   0.11284217  0.08208896]\n",
      "---------------\n",
      "ASIN: B0031BW7Y2\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [ 0.05705893 -0.03719502  0.44170085  0.06803118  0.24020387]\n",
      "---------------\n",
      "ASIN: B00V6X30SE\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [ 0.05012938 -0.0244224   0.5908535   0.06344365  0.18704775]\n",
      "---------------\n",
      "ASIN: B000C9WJ8K\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [ 0.08082797 -0.15266147  0.5634266   0.10604882  0.18264209]\n",
      "---------------\n",
      "ASIN: B000CSIRXW\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [0.01095499 0.03739156 0.46243435 0.05632354 0.09468334]\n",
      "---------------\n",
      "ASIN: B00A6G5SB4\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [ 0.11313607 -0.03140498  0.52315724  0.11893257  0.20694906]\n",
      "---------------\n",
      "ASIN: B00E7AKKCM\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.02058313  0.05381123  0.4490339   0.07459264  0.12543821]\n",
      "---------------\n",
      "ASIN: B00UCY60GW\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.09311832  0.01523276  0.55788386  0.08014666  0.18191735]\n",
      "---------------\n",
      "ASIN: B004323RQK\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [0.00467857 0.01351286 0.34701225 0.05617493 0.21290135]\n",
      "---------------\n",
      "ASIN: B005CWSBT8\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.082068    0.00861483  0.69367355  0.06404637  0.11748557]\n",
      "---------------\n",
      "ASIN: B004EIDD2Q\n",
      "Review: 5.0\n",
      "Embedding shape: (768,)\n",
      "Embedding sample (first 5 values): [-0.09755012 -0.0503799   0.6631498   0.14444216  0.09943242]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_and_display_data(pickle_file):\n",
    "    data = []\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        while True:\n",
    "            try:\n",
    "                trajectory = pickle.load(file)\n",
    "                data.append(trajectory)\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    print(f\"Loaded data from {pickle_file}\")\n",
    "    print(f\"Total number of trajectories: {len(data)}\")\n",
    "\n",
    "    if data:\n",
    "        print(f\"\\n[FIRST TRAJECTORY]\")\n",
    "        first_trajectory = data[0]\n",
    "        for product in first_trajectory:\n",
    "            print(f\"ASIN: {product['asin']}\")\n",
    "            print(f\"Review: {product['review']}\")\n",
    "            print(f\"Embedding shape: {product['embedding'].shape}\")\n",
    "            print(f\"Embedding sample (first 5 values): {product['embedding'][:5]}\")\n",
    "            print(\"---------------\")\n",
    "\n",
    "# ===============[ EXECUTE ]===============\n",
    "pickle_file = \"data/embeddings/distilbert/embeddings_768.pckl\"\n",
    "load_and_display_data(pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
